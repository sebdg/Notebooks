{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (0.2.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain)\n",
      "  Downloading langchain_core-0.2.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.77-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/sebdg/anaconda3/envs/tf3/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.2.7-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.6/315.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, orjson, mypy-extensions, marshmallow, jsonpointer, greenlet, annotated-types, typing-inspect, SQLAlchemy, pydantic, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.30 annotated-types-0.7.0 dataclasses-json-0.6.7 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.7 langchain-text-splitters-0.2.1 langchain_community-0.2.5 langsmith-0.1.77 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.5 pydantic-2.7.4 pydantic-core-2.18.4 tenacity-8.3.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion_detection_and_classification',\n",
       " 'emotion_generation',\n",
       " 'emotion_analysis',\n",
       " 'conversational_context',\n",
       " 'emotional_summarization',\n",
       " 'emotion_comparison',\n",
       " 'emotion_explanation',\n",
       " 'emotion_detection_in_social_media',\n",
       " 'emotion_engagement',\n",
       " 'emotion_based_recommendations',\n",
       " 'emotion_and_context',\n",
       " 'cross_domain_emotion_detection',\n",
       " 'creative_writing_with_emotions',\n",
       " 'combining_emotions_with_other_data',\n",
       " 'multi_modal_emotion_analysis',\n",
       " 'emotion_based_querying',\n",
       " 'complex_emotion_tasks',\n",
       " 'integrating_emotions_in_machine_learning_workflows']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('prompts.json', \"r\", encoding=\"utf-8\") as json_file:\n",
    "    task_prompts = json.load(json_file)\n",
    "\n",
    "list(task_prompts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotion_detection_and_classification': ['emotions', 'sentence'], 'emotion_generation': ['emotions', 'sentence'], 'emotion_analysis': ['emotions', 'sentence'], 'conversational_context': ['emotions', 'response', 'response_style', 'second_sentence', 'sentence'], 'emotional_summarization': ['emotions', 'sentence'], 'emotion_comparison': ['emotions', 'second_sentence', 'sentence'], 'emotion_explanation': ['emotions', 'response', 'sentence'], 'emotion_detection_in_social_media': ['emotions', 'sentence'], 'emotion_based_recommendations': ['response', 'sentence'], 'emotion_and_context': ['context', 'emotions', 'response', 'sentence'], 'cross_domain_emotion_detection': ['emotions', 'sentence'], 'creative_writing_with_emotions': ['emotions', 'sentence'], 'combining_emotions_with_other_data': ['emotions', 'sentence'], 'multi_modal_emotion_analysis': ['emotions', 'image_description', 'sentence'], 'emotion_based_querying': ['emotions', 'response'], 'complex_emotion_tasks': ['emotions', 'sentence'], 'integrating_emotions_in_machine_learning_workflows': ['emotions', 'sentence']}\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "# recognize the placeholders in the prompt {placeholder}\n",
    "def find_placeholders(prompt):\n",
    "    return re.findall(r'\\{([^\\}]*)\\}', prompt)\n",
    "\n",
    "\n",
    "placeholders = set()\n",
    "task_placeholders = {}\n",
    "for task, prompts in task_prompts.items():\n",
    "    prompt_placeholders = list()\n",
    "    for prompt in prompts:\n",
    "        assert \"input_template\" in prompt, f\"input_template missing for {task}\"\n",
    "        assert \"output_template\" in prompt, f\"output_template missing for {task}\"\n",
    "        assert prompt.keys() == {\"input_template\", \"output_template\"}, f\"unknown keys in prompt for {task}\"\n",
    "        input_placeholders = find_placeholders(prompt[\"input_template\"])\n",
    "        output_placeholders = find_placeholders(prompt[\"output_template\"])\n",
    "        placeholders.update(input_placeholders)\n",
    "        placeholders.update(output_placeholders)\n",
    "        prompt_placeholders = list(set(prompt_placeholders + input_placeholders + output_placeholders))\n",
    "    prompt_placeholders.sort()\n",
    "    task_placeholders[task] = prompt_placeholders\n",
    "\n",
    "print(task_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion_detection_and_classification',\n",
       " 'emotion_generation',\n",
       " 'emotion_analysis',\n",
       " 'emotional_summarization',\n",
       " 'emotion_detection_in_social_media',\n",
       " 'cross_domain_emotion_detection',\n",
       " 'creative_writing_with_emotions',\n",
       " 'combining_emotions_with_other_data',\n",
       " 'complex_emotion_tasks',\n",
       " 'integrating_emotions_in_machine_learning_workflows']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take tasks with the same placeholders ['emotions', 'sentence']\n",
    "tasks = [task for task, task_placeholders in task_placeholders.items() if task_placeholders == ['emotions', 'sentence']]\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.memory.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_parquet(\"go_emotions_train.parquet\")\n",
    "test = pd.read_parquet(\"go_emotions_test.parquet\")\n",
    "emotions = train.columns[1:29].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = f\"\"\"\\\n",
    "You are an expert in emotions detection and generation, you will be given different textual tasks to related to the go_emotions dataset.\n",
    "Only perform the required task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_emotions_to_string(array_of_labels):\n",
    "    \"\"\"Decode the emotions from the row to a list of strings.\"\"\"\n",
    "    # active labels are 1, inactive are 0\n",
    "    return [emotion for i, emotion in enumerate(emotions) if array_of_labels[emotion] == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_template': \"Identify the emotional tone present in the given statement: '{sentence}'.\",\n",
       "  'output_template': \"The sentence expresses: '{emotions}'.\"},\n",
       " {'input_template': \"Classify the emotions expressed in the following sentence: '{sentence}'\",\n",
       "  'output_template': '{emotions}'},\n",
       " {'input_template': \"Identify all the emotions present in the following sentence: '{sentence}'\",\n",
       "  'output_template': '{emotions}'},\n",
       " {'input_template': \"Classify the emotions and their intensity in the following sentence: '{sentence}'\",\n",
       "  'output_template': '{emotions}'}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_prompts[\"emotion_detection_and_classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admiration',\n",
       " 'amusement',\n",
       " 'anger',\n",
       " 'annoyance',\n",
       " 'approval',\n",
       " 'caring',\n",
       " 'confusion',\n",
       " 'curiosity',\n",
       " 'desire',\n",
       " 'disappointment',\n",
       " 'disapproval',\n",
       " 'disgust',\n",
       " 'embarrassment',\n",
       " 'excitement',\n",
       " 'fear',\n",
       " 'gratitude',\n",
       " 'grief',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'nervousness',\n",
       " 'optimism',\n",
       " 'pride',\n",
       " 'realization',\n",
       " 'relief',\n",
       " 'remorse',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_detections = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309090 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "model_name = \"phi3\"\n",
    "all_emotions = emotions\n",
    "pp = list(task_prompts[\"emotion_engagement\"])\n",
    "\n",
    "target_tasks = [\"emotion_detection_and_classification\", \"emotion_engagement\", \"emotion_generation\", \"emotion_analysis\", \"emotion_based_recommendations\"]\n",
    "for target_task in target_tasks:\n",
    "    for index, row in train.iterrows():\n",
    "        prompt = random.choice(pp)\n",
    "        matching = decode_emotions_to_string(row[emotions])\n",
    "        formatted_input = prompt[\"input_template\"].format(emotions=\", \".join(matching),sentence=row[\"text\"], response=\"\")\n",
    "        formatted_output = prompt[\"output_template\"].format(emotions=\", \".join(matching),sentence=row[\"text\"], response=\"\") \n",
    "        model_detections.append({\n",
    "            \"model\": model_name,\n",
    "            \"text\":  row[\"text\"], \n",
    "            \"formatted_input\": formatted_input, \n",
    "            \"emotions\": \", \".join(matching), \n",
    "            \"formatted_output\": formatted_output,\n",
    "            \"response\": \"\",\n",
    "            \n",
    "            })\n",
    "print(len(model_detections),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309090"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_df = pd.DataFrame(model_detections)\n",
    "with open(\"model_prompts.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(new_df.to_json(orient=\"records\", lines=True))\n",
    "new_df.to_sql(\"model_prompts\", \"sqlite:///model_prompts.db\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [44:16<00:00,  1.13it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>text</th>\n",
       "      <th>formatted_input</th>\n",
       "      <th>emotions</th>\n",
       "      <th>response</th>\n",
       "      <th>formatted_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>As long as the minority aren't \"minorities\" I ...</td>\n",
       "      <td>Classify the emotions and their intensity in t...</td>\n",
       "      <td>[anger, disapproval]</td>\n",
       "      <td>Here are the detected emotions:\\n\\n* **disappr...</td>\n",
       "      <td>anger, disapproval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Same, I still need to sleep to go to work tomo...</td>\n",
       "      <td>Classify the emotions expressed in the followi...</td>\n",
       "      <td>[disappointment, sadness, neutral]</td>\n",
       "      <td>The emotions present in this text are:\\n\\n* **...</td>\n",
       "      <td>disappointment, sadness, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Bide your time, keep your eyes open, and build...</td>\n",
       "      <td>Identify all the emotions present in the follo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Here are the emotions I detect:\\n\\n* **patienc...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Clock the flair but What are the judges on? I ...</td>\n",
       "      <td>Classify the emotions expressed in the followi...</td>\n",
       "      <td>[amusement, relief, surprise]</td>\n",
       "      <td>Here are the emotions I detected:\\n\\n* **Surpr...</td>\n",
       "      <td>amusement, relief, surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Who's the top three craft brewers in the area??</td>\n",
       "      <td>Classify the emotions expressed in the followi...</td>\n",
       "      <td>[curiosity]</td>\n",
       "      <td>Based on the sentence, I detect the presence o...</td>\n",
       "      <td>curiosity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Not sure how you could put [NAME] there, he's ...</td>\n",
       "      <td>Identify all the emotions present in the follo...</td>\n",
       "      <td>[anger, disapproval]</td>\n",
       "      <td>The emotions present in this sentence are:\\n\\n...</td>\n",
       "      <td>anger, disapproval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>No, the teens were not being assholes. The ori...</td>\n",
       "      <td>Classify the emotions expressed in the followi...</td>\n",
       "      <td>[anger, disapproval]</td>\n",
       "      <td>The emotions present in this text are:\\n\\n* **...</td>\n",
       "      <td>anger, disapproval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Uh oh. Ummm, I need to take care of something.</td>\n",
       "      <td>Identify the emotional tone present in the giv...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Based on the text, I identify the following em...</td>\n",
       "      <td>The sentence expresses: ''.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Looking at the thread now, it seems that this ...</td>\n",
       "      <td>Identify all the emotions present in the follo...</td>\n",
       "      <td>[disappointment]</td>\n",
       "      <td>The emotions present in the sentence are:\\n\\n*...</td>\n",
       "      <td>disappointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>Disconcerting how much I see this guy’s trash ...</td>\n",
       "      <td>Identify all the emotions present in the follo...</td>\n",
       "      <td>[annoyance, disgust]</td>\n",
       "      <td>The emotions present in this sentence are:\\n\\n...</td>\n",
       "      <td>annoyance, disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                                               text  \\\n",
       "0     llama3:8b  As long as the minority aren't \"minorities\" I ...   \n",
       "1     llama3:8b  Same, I still need to sleep to go to work tomo...   \n",
       "2     llama3:8b  Bide your time, keep your eyes open, and build...   \n",
       "3     llama3:8b  Clock the flair but What are the judges on? I ...   \n",
       "4     llama3:8b    Who's the top three craft brewers in the area??   \n",
       "...         ...                                                ...   \n",
       "2995  llama3:8b  Not sure how you could put [NAME] there, he's ...   \n",
       "2996  llama3:8b  No, the teens were not being assholes. The ori...   \n",
       "2997  llama3:8b     Uh oh. Ummm, I need to take care of something.   \n",
       "2998  llama3:8b  Looking at the thread now, it seems that this ...   \n",
       "2999  llama3:8b  Disconcerting how much I see this guy’s trash ...   \n",
       "\n",
       "                                        formatted_input  \\\n",
       "0     Classify the emotions and their intensity in t...   \n",
       "1     Classify the emotions expressed in the followi...   \n",
       "2     Identify all the emotions present in the follo...   \n",
       "3     Classify the emotions expressed in the followi...   \n",
       "4     Classify the emotions expressed in the followi...   \n",
       "...                                                 ...   \n",
       "2995  Identify all the emotions present in the follo...   \n",
       "2996  Classify the emotions expressed in the followi...   \n",
       "2997  Identify the emotional tone present in the giv...   \n",
       "2998  Identify all the emotions present in the follo...   \n",
       "2999  Identify all the emotions present in the follo...   \n",
       "\n",
       "                                emotions  \\\n",
       "0                   [anger, disapproval]   \n",
       "1     [disappointment, sadness, neutral]   \n",
       "2                                     []   \n",
       "3          [amusement, relief, surprise]   \n",
       "4                            [curiosity]   \n",
       "...                                  ...   \n",
       "2995                [anger, disapproval]   \n",
       "2996                [anger, disapproval]   \n",
       "2997                                  []   \n",
       "2998                    [disappointment]   \n",
       "2999                [annoyance, disgust]   \n",
       "\n",
       "                                               response  \\\n",
       "0     Here are the detected emotions:\\n\\n* **disappr...   \n",
       "1     The emotions present in this text are:\\n\\n* **...   \n",
       "2     Here are the emotions I detect:\\n\\n* **patienc...   \n",
       "3     Here are the emotions I detected:\\n\\n* **Surpr...   \n",
       "4     Based on the sentence, I detect the presence o...   \n",
       "...                                                 ...   \n",
       "2995  The emotions present in this sentence are:\\n\\n...   \n",
       "2996  The emotions present in this text are:\\n\\n* **...   \n",
       "2997  Based on the text, I identify the following em...   \n",
       "2998  The emotions present in the sentence are:\\n\\n*...   \n",
       "2999  The emotions present in this sentence are:\\n\\n...   \n",
       "\n",
       "                      formatted_output  \n",
       "0                   anger, disapproval  \n",
       "1     disappointment, sadness, neutral  \n",
       "2                                       \n",
       "3          amusement, relief, surprise  \n",
       "4                            curiosity  \n",
       "...                                ...  \n",
       "2995                anger, disapproval  \n",
       "2996                anger, disapproval  \n",
       "2997       The sentence expresses: ''.  \n",
       "2998                    disappointment  \n",
       "2999                annoyance, disgust  \n",
       "\n",
       "[3000 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "model_name = \"llama3:8b\"\n",
    "chat = ChatOllama(model=model_name, temperature=0.5)\n",
    "generator = prompt_for_response | chat\n",
    "\n",
    "# Function to process each task\n",
    "def process_task(index):\n",
    "    prompt = random.choice(task_prompts[\"emotion_detection_and_classification\"])\n",
    "    formatted_input = prompt[\"input_template\"].format(sentence=train.iloc[index, 0])\n",
    "    response = generator.invoke({\"input\": formatted_input})\n",
    "    \n",
    "    matching = [emotion for emotion in emotions if f\"**{emotion}**\" in response.content.lower()]\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"text\": train.iloc[index, 0], \n",
    "        \"formatted_input\": formatted_input, \n",
    "        \"emotions\": matching, \n",
    "        \"response\": response.content,\n",
    "        \"formatted_output\": prompt[\"output_template\"].format(emotions=\", \".join(matching))\n",
    "    }\n",
    "\n",
    "# Running tasks in parallel\n",
    "model_detections = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Using list comprehension with tqdm for progress bar\n",
    "    results = list(tqdm(executor.map(process_task, range(3000)), total=3000))\n",
    "\n",
    "# Converting results to DataFrame\n",
    "new_df = pd.DataFrame(results)\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\\\n",
    "You are a prompting assistant, please paraphrase the provided prompt, while retaining the meaning and the exact placeholders in curly braquets.\n",
    "Only generate the requested part(input_template, output_template) of the prompt.\n",
    "While you may paraphrase the prompt, please do not change the meaning of the prompt, and the placeholders.\n",
    "Remain concise and to the point. Do not include any additional information such as examples or explanations.\n",
    "DO not add additional constraints or requirements. DO not change any of the placeholders in the prompt(input_template, output_template).\n",
    "The new prompt should be in the same format as the original prompt and a single sentence.\n",
    "Do not add the task name or any other information to the prompt.\n",
    "If you succeed in paraphrasing the prompt, you will get a 1000 points. If you fail, you will get 0 points.\n",
    "Your mission is critical, take a deep braeth and focus on the task at hand. Good luck!\\\n",
    " \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generator =  prompt_generation_prompt | chat\n",
    "history_for_chain = ChatMessageHistory()\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    generator,\n",
    "    lambda session_id: history_for_chain,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_for_chain = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_for_chain.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run de892c14-7c04-4b37-9aa1-3eb1960cbbb2 not found for run 0d1c6883-68b2-4ee7-b98f-a07a2ae17822. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion_detection_and_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 986878b6-bd3a-4bf3-8a2a-4613ae122f31 not found for run 5e4ab6b4-20c4-4227-b422-bdf9a727ea5b. Treating as a root run.\n",
      "Parent run 8a82bc14-1e06-446c-8310-56268c69a52e not found for run 510a8e02-6a5f-4472-b02b-3a2126d93d76. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determine the sentiment conveyed by the given phrase: '{sentence}'.\n",
      "{emotions}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run b800faa7-b844-4b64-ae1f-da5782c3524c not found for run ddf4e43a-9c05-47bc-a8ff-78c085c33ffd. Treating as a root run.\n",
      "Parent run 92f29293-5794-4f18-9fb4-f8c917538b44 not found for run ee240945-2f08-499a-ae0b-8d64ac209f31. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify the emotional tone of the given statement: '{sentence}'.\n",
      "{emotions}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 73295dd6-2cd2-4e35-a944-9f837b10785d not found for run 3754c908-4673-4ba7-a370-f9b3fa74769d. Treating as a root run.\n",
      "Parent run 610e44ec-d2ee-4406-acc8-028832689d81 not found for run 90562f3f-e350-429e-bce8-a59ea45b2063. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the emotional sentiment of the phrase: '{sentence}'.\n",
      "{emotions}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newprompts = {}\n",
    "for task in task_prompts:\n",
    "    print(task)\n",
    "    newprompts[task] = []\n",
    "    history_for_chain = ChatMessageHistory()\n",
    "    for prompt in task_prompts[task]:\n",
    "        input_placeholders = find_placeholders(prompt[\"input_template\"])\n",
    "        output_placeholders = find_placeholders(prompt[\"output_template\"])\n",
    "        for i in range(5):\n",
    "\n",
    "            response = chain_with_message_history.invoke(\n",
    "                {\"input\": f\"Generate a prompt template paraphrasing : \" + prompt[\"input_template\"]},\n",
    "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "            )\n",
    "            new_input = response.content.strip().split(\"\\n\")[0].strip()\n",
    "            new_input_placeholders = find_placeholders(new_input)\n",
    "            if set(new_input_placeholders) != set(input_placeholders):\n",
    "                print(\"input placeholders mismatch\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            response = chain_with_message_history.invoke(\n",
    "                {\"input\": f\"Now generate the output_template, paraphrasing : \" + prompt[\"output_template\"]},\n",
    "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
    "            )\n",
    "            new_output = response.content.strip().split(\"\\n\")[0].strip()\n",
    "            new_output_placeholders = find_placeholders(new_output)\n",
    "            if set(new_output_placeholders) != set(output_placeholders):\n",
    "                print(\"output placeholders mismatch\")\n",
    "                continue\n",
    "\n",
    "            newprompts[task].append({\"input_template\": new_input,\"output_template\": new_output})\n",
    "            print(new_input)\n",
    "            print(new_output)\n",
    "            print()\n",
    "\n",
    "    with open('newprompts.json', \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(newprompts, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'phi3',\n",
       " 'created_at': '2024-06-17T00:45:09.0916345Z',\n",
       " 'response': ' Categorize the feelings conveyed in the given statement: \"{sentence}\"',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'context': [32006,\n",
       "  887,\n",
       "  526,\n",
       "  263,\n",
       "  9508,\n",
       "  292,\n",
       "  20255,\n",
       "  29892,\n",
       "  3113,\n",
       "  337,\n",
       "  1742,\n",
       "  278,\n",
       "  4944,\n",
       "  9508,\n",
       "  29892,\n",
       "  1550,\n",
       "  11551,\n",
       "  292,\n",
       "  278,\n",
       "  6593,\n",
       "  322,\n",
       "  278,\n",
       "  2058,\n",
       "  8948,\n",
       "  414,\n",
       "  297,\n",
       "  3151,\n",
       "  368,\n",
       "  4105,\n",
       "  339,\n",
       "  1691,\n",
       "  29889,\n",
       "  32007,\n",
       "  32010,\n",
       "  4134,\n",
       "  1598,\n",
       "  278,\n",
       "  23023,\n",
       "  1080,\n",
       "  13384,\n",
       "  297,\n",
       "  278,\n",
       "  1494,\n",
       "  10541,\n",
       "  29901,\n",
       "  22372,\n",
       "  18616,\n",
       "  663,\n",
       "  10162,\n",
       "  32007,\n",
       "  32001,\n",
       "  315,\n",
       "  20440,\n",
       "  675,\n",
       "  278,\n",
       "  21737,\n",
       "  27769,\n",
       "  287,\n",
       "  297,\n",
       "  278,\n",
       "  2183,\n",
       "  3229,\n",
       "  29901,\n",
       "  29850,\n",
       "  18616,\n",
       "  663,\n",
       "  5038,\n",
       "  32007],\n",
       " 'total_duration': 503039400,\n",
       " 'load_duration': 1516500,\n",
       " 'prompt_eval_count': 51,\n",
       " 'prompt_eval_duration': 349708000,\n",
       " 'eval_count': 17,\n",
       " 'eval_duration': 149952000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/akshayjambhulkar/telecom-conversational-support-chat-pre-processed-with-agent/data/train-00000-of-00001.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"conv\"] = df[\"text\"].apply(lambda x: str(x).replace(\"agent:\",\"\\n\\nagent:\\n\").replace(\"client:\", \"\\n\\nclient:\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "agent:\n",
       " Good afternoon, thank you for calling Union Mobile. My name is Marcy, how can I assist you today? \n",
       "\n",
       "client:\n",
       " Hi Marcy, I'm calling to inquire about the cost of your mobile cloud plans. I'm tired of my current plan and want to switch to a better one. \n",
       "\n",
       "agent:\n",
       " Of course, I'd be happy to help you with that. Can you please verify your identity by providing me with your account PIN or the last four digits of the credit card associated with your account? \n",
       "\n",
       "client:\n",
       " Sure, my account PIN is 1234. \n",
       "\n",
       "agent:\n",
       " Great, thank you for providing that. Now, let me check on available mobile cloud plans and their corresponding costs. We have three different plans that you can choose from, depending on your needs. \n",
       "\n",
       "client:\n",
       " Okay, what are they? \n",
       "\n",
       "agent:\n",
       " Our first plan is the \" Plan, which costs $5 per month and includes 5GB of data, 500 minutes of talk time, and unlimited text messages. The second plan is the Pro Plan, which costs $15 per month and includes 20GB of data, 1000 minutes of talk time, and unlimited text messages. Finally, we have the Premium Plan, which costs $30 per month and includes 50GB of data, 2000 minutes of talk time, and unlimited text messages. \n",
       "\n",
       "client:\n",
       " That sounds good. But can you tell me more about the data spe and how it works? \n",
       "\n",
       "agent:\n",
       " Absolutely. Our mobile cloud plans come with different data limitsances, which means you you can use up to a certain amount of data per month without incurring additional charges. If you exceed your data allowance, you'll be charged an additional fee per gigabyte used. However, we also offer data rollover, which means that any unused data from the previous month will be carried over to the next month. \n",
       "\n",
       "client:\n",
       " That sounds sense. What if I want to upgrade or downgrade my plan? \n",
       "\n",
       "agent:\n",
       " You can upgrade or downgrade your plan at any time by contacting our customer service team. Keep in mind that if you upgrade your plan, you'll need to pay the difference between the old and new plan prices. If you downgrade your plan, you'll receive a prorated credit for the remaining days in your billing cycle. \n",
       "\n",
       "client:\n",
       " Okay, I think I'll go with the Pro Plan. How do I sign up? \n",
       "\n",
       "agent:\n",
       " Great choice! I can take you with that. Can you please confirm your emaililling information and provide me with your email address so I can send you a copy of your new plan details? \n",
       "\n",
       "client:\n",
       " Sure, my email address is [marquis@email.com](mailto:marquis@email.com). And my billing information is... (provides billing information) \n",
       "\n",
       "agent:\n",
       " Thank you, Marquis. I've updated your account with your new plan selection. You'll receive a confirmation email with all the details shortly. Is there anything else I can assist you with today? \n",
       "\n",
       "client:\n",
       " No, that's all. Thanks for your help, Marcy. \n",
       "\n",
       "agent:\n",
       " You're welcome, Marquis. It was my pleasure to assist you. Have a great day!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(df[\"conv\"].iloc[15206]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
